 
**Global Narrative Consistency Detection**

### **Team: HackHers**

**Members:**

* **Mrunali Kamerikar** *(Team Leader)*
* **Riddhima Taose**


This project solves the **Global Narrative Consistency Challenge** by determining whether a hypothetical backstory for a character is logically compatible with a long-form novel (100k+ words).

The task is formulated as a **binary classification problem**:

* **1** â†’ Backstory is consistent
* **0** â†’ Backstory contradicts the narrative

Our system combines:

* Long-context document retrieval
* Semantic embeddings
* Natural Language Inference (NLI)
* Pathway-based orchestration (Track A requirement)


## ğŸ§© Approach Summary

The model follows four steps:

### 1. **Long-Context Chunking**

Each novel is split into fixed-size text chunks.
This allows efficient processing of 100k+ word documents without losing local context.

### 2. **Semantic Retrieval**

Backstories are embedded using `SentenceTransformers`.
The most relevant novel chunks are retrieved via cosine similarity.

### 3. **Contradiction Detection**

Each retrieved chunk is evaluated against the backstory using a pretrained **RoBERTa-MNLI** model.
The MNLI model outputs a probability that the chunk **contradicts** the backstory.

### 4. **Decision Logic**

If **any retrieved chunk** strongly contradicts the backstory â†’ label = **0**
Otherwise â†’ label = **1**

Thresholds are calibrated using the training set.


## ğŸ§ª Why This Works

Narrative consistency is **existential**, not statistical:

> A single strong contradiction is enough to invalidate a backstory.

Using **maximum contradiction** instead of averaging ensures that even one incompatible scene is detected, which matches the causal-consistency requirement of the challenge.


## ğŸ“‚ Project Structure

```
iit_hackathon/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Dataset/
â”‚       â”œâ”€â”€ Books/          # Full novels
â”‚       â”œâ”€â”€ train.csv
â”‚       â””â”€â”€ test.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ load_data.py        # Loads dataset
â”‚   â”œâ”€â”€ chunk.py           # Splits novels
â”‚   â”œâ”€â”€ ingest.py          # Pathway ingestion
â”‚   â”œâ”€â”€ retrieve.py        # Semantic retrieval
â”‚   â”œâ”€â”€ judge.py           # MNLI contradiction logic
â”‚   â”œâ”€â”€ fast_tune.py       # Threshold tuning
â”‚   â””â”€â”€ main.py            # End-to-end pipeline
â”‚
â”œâ”€â”€ best_threshold.txt
â”œâ”€â”€ results.csv
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


## âš™ï¸ Installation

Use **Python 3.10**.

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```


## â–¶ï¸ Running the System

### Step 1 â€” Tune the contradiction threshold

This uses `train.csv` to calibrate the MNLI contradiction scores.

```bash
python src/fast_tune.py
```

This creates:

```
best_threshold.txt
```


### Step 2 â€” Generate predictions

```bash
python src/main.py
```

This produces:

```
results.csv
```

Format:

```
StoryID,Prediction
12,1
48,0
...
```


## ğŸ§  Models Used

| Component               | Model                                    |
| ----------------------- | ---------------------------------------- |
| Embeddings              | `sentence-transformers/all-MiniLM-L6-v2` |
| Contradiction Detection | `roberta-large-mnli`                     |
| Orchestration           | `Pathway`                                |


## ğŸ“Š Track A Compliance

This system fulfills all Track-A requirements:

* Uses **Pathway** for long-document ingestion
* Handles **100k+ token novels**
* Performs **evidence-based reasoning**
* Produces **binary predictions**
* Fully **reproducible**


## âš ï¸ Limitations

* NLI models reason locally; extremely subtle long-term dependencies may be missed.
* Chunking may occasionally separate cause and effect across boundaries.
* Very vague backstories may not trigger strong contradiction signals.


## ğŸ Final Note

This system is designed for **robust narrative-level consistency detection**, not surface-level keyword matching. It prioritizes logical contradictions, causal incompatibilities, and semantic mismatch across long contexts â€” exactly what this hackathon evaluates.

